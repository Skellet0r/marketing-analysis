{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data exploration will mainly focus on answering some questions related to customers and their value. We want to also get some insight into what our client's customer base looks like for when we start doing our market segmentation and later our modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Questions:\n",
    "\n",
    "1. What is the purchasing history by country ?\n",
    "2. Identify any cyclical nature of purchasing by country ?\n",
    "3. What other ways are there to segment our customers ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T01:58:57.085515Z",
     "start_time": "2020-10-28T01:58:57.053432Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from plotly.offline import init_notebook_mode\n",
    "\n",
    "from ipywidgets import widgets, interact\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(font_scale=1.2)\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T01:57:13.230674Z",
     "start_time": "2020-10-28T01:57:07.435562Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(\"../data/interim/data.csv\", index_col=\"invoice_date\", parse_dates=True)\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T01:57:13.266092Z",
     "start_time": "2020-10-28T01:57:13.233714Z"
    }
   },
   "outputs": [],
   "source": [
    "# output first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping by Country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purchasing History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset has a country feature, I want to see the purchasing history by country over time, and identify where the majority of purchasing is coming from. This will be beneficial in our pursuit of segmenting the customer base, as we can possibly use country of origin as a way to segment the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T01:57:13.981262Z",
     "start_time": "2020-10-28T01:57:13.269875Z"
    }
   },
   "outputs": [],
   "source": [
    "# pivot table of quarterly gross invoice total by country\n",
    "quarterly_gross_country = pd.pivot_table(df, index=pd.Grouper(freq=\"Q\"), columns=\"country\", values=\"total\", aggfunc=\"sum\")\n",
    "fig = px.scatter(quarterly_gross_country, title=\"Quarterly Gross Purchasing by Country\", labels={\"value\": \"Gross\", \"invoice_date\": \"Quarter End Date\", \"country\": \"Country\"})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noticeably looking at the quarterly gross, without any filtering, we can see that the United Kingdom originates the most purchasing. Historically they have purchased somewhere between 700k to 3M each quarter, outspending the rest of the countries by a large factor. I'll also want to inspect how many customers we have throughout the various countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T01:57:15.156787Z",
     "start_time": "2020-10-28T01:57:13.982854Z"
    }
   },
   "outputs": [],
   "source": [
    "# import geojson\n",
    "with open(\"../data/external/countries.geojson\") as f:\n",
    "    countries = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T01:57:15.168326Z",
     "start_time": "2020-10-28T01:57:15.158597Z"
    }
   },
   "outputs": [],
   "source": [
    "# do we have the geojson for all the countries in our dataframe\n",
    "geojson_countries = set(map(lambda x: x['properties']['ADMIN'], countries['features']))\n",
    "df_countries = set(df.country.unique())\n",
    "\n",
    "df_countries - geojson_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T01:57:15.249520Z",
     "start_time": "2020-10-28T01:57:15.170798Z"
    }
   },
   "outputs": [],
   "source": [
    "# map the countries missing to one that is available\n",
    "mapping = {\n",
    "    'Channel Islands': \"France\",  # since they're closest to France\n",
    "    'Czech Republic': \"Czechia\",\n",
    "    'EIRE': \"Ireland\",\n",
    "    'European Community': \"European Union\",\n",
    "    'Hong Kong': \"Hong Kong S.A.R.\",\n",
    "    'Korea': \"South Korea\",\n",
    "    'RSA': \"South Africa\",\n",
    "    'USA': \"United States of America\",\n",
    "    'Unspecified': \"Unspecified\",\n",
    "    'West Indies': \"Cuba\"  # west indies is 18 countries but this is close enough\n",
    "}\n",
    "df['updated_country'] = df.country.replace(mapping)\n",
    "set(df['updated_country']) - geojson_countries  # left over missing countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T01:57:36.379307Z",
     "start_time": "2020-10-28T01:57:15.258444Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plot chloropleth map of total purchasing value by region\n",
    "total_by_country = np.log(df.groupby(\"updated_country\").sum()[\"total\"]).reset_index()\n",
    "fig = px.choropleth_mapbox(\n",
    "    data_frame=total_by_country,\n",
    "    geojson=countries,\n",
    "    featureidkey=\"properties.ADMIN\",\n",
    "    locations=\"updated_country\",\n",
    "    color=\"total\",\n",
    "    mapbox_style=\"carto-positron\",\n",
    "    zoom=1,\n",
    "    title=\"Regional Sales Rating\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the map of total sales value by country (the numbers are scaled down using the natural log), there appears to be an decreasing value the further the region is from the UK. There are exceptions, but the overall picture describes that, and maybe the economic status of the region itself plays a role in the purchasing power of customers in that region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T01:57:36.482449Z",
     "start_time": "2020-10-28T01:57:36.382584Z"
    }
   },
   "outputs": [],
   "source": [
    "# unique customers by region\n",
    "region_counts = pd.DataFrame(df.drop_duplicates([\"customer_id\", \"country\"]).value_counts(\"country\"), columns=[\"count\"]).reset_index()\n",
    "fig = px.bar(region_counts, x=\"country\", y=\"count\", title=\"Unique Customers by Region\", \n",
    "       labels={\"country\": \"Region\", \"count\": \"# of Customers\"})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the majority of our customer base is in the UK, with the rest of the regions trailing with a range from 1 to 107. In descending order we have Germany, France, Spain, Belgium as the runner ups. Looks like if we wanted to segment solely by region we might run into an issue, and would only market in the UK. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look into the purchasing habits of countries, by plotting the time series of their gross invoices either weekly, monthly, or quarterly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-28T01:57:37.093871Z",
     "start_time": "2020-10-28T01:57:36.484322Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# function to plot the time series of invoice sum\n",
    "from warnings import filterwarnings\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "periods = {\"Month\": \"M\", \"Quarter\": \"Q\", \"Week\": \"W\"}\n",
    "def plot_country_time_series(country, period):\n",
    "    _period = periods[period]\n",
    "    _df = df.loc[df[\"country\"] == country, \"total\"].groupby(pd.Grouper(freq=_period)).sum()\n",
    "    _df.plot(figsize=(16, 9), title=f\"{country} - {period} Gross Purchasing (in GBP)\", style=\"o-\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Invoice Total (in GBP)\")\n",
    "    \n",
    "\n",
    "countries = widgets.Dropdown(options=df.country.unique(), description=\"Country:\")\n",
    "periods_ = widgets.Dropdown(options=list(periods.keys()), description=\"Period:\")\n",
    "\n",
    "interact(plot_country_time_series, country=countries, period=periods_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regionally we can see that certain countries have different ranges of time between purchasing. This tells us that on the customer level, we have customers which have large gaps between their purchases. We will definitely have to engineer some features to help us with segmenting the customer base, especially over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative Segmentation Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking through our data we will have to generate new features for segmenting our customers. In marketing analysis a common way to identify best customers is to use the RFM model.\n",
    "\n",
    "> Recency, frequency, monetary value is a marketing analysis tool used to identify a company's or an organization's best customers by using certain measures. The RFM model is based on three quantitative factors:\n",
    "\n",
    "- Recency: How recently a customer has made a purchase\n",
    "- Frequency: How often a customer makes a purchase\n",
    "- Monetary Value: How much money a customer spends on purchases\n",
    "\n",
    "You can read more about RFM here: https://www.investopedia.com/terms/r/rfm-recency-frequency-monetary-value.asp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll have to create the following features for each customer through each month:\n",
    "\n",
    "- Recency = the number of months that have passed since the customer last purchased\n",
    "- Frequency = the number of purchases by the customer\n",
    "- Monetary = the highest value of all invoices by the customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load raw dataset\n",
    "raw_df = pd.read_csv(\"../data/raw/data.csv\", parse_dates=True, index_col=\"InvoiceDate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split date_column into date and time and add value of purchase column\n",
    "raw_df[\"invoice_date\"] = raw_df.index.date\n",
    "raw_df[\"invoice_time\"] = raw_df.index.time\n",
    "raw_df[\"value\"] = raw_df.Quantity * raw_df.Price  # the value of the purchase\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our end result will be a dataframe, with a row for each customer each month, and the RFM values for that customer for that month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with invoices and their total value\n",
    "invoices_df = raw_df.groupby([\"Customer ID\", \"invoice_date\", \"Invoice\"]).sum()\\\n",
    "                    .reset_index()[[\"Customer ID\", \"invoice_date\", \"Invoice\", 'value']]\n",
    "invoices_df[\"invoice_date\"] = pd.to_datetime(invoices_df.invoice_date)\n",
    "invoices_df.set_index(\"invoice_date\", inplace=True)\n",
    "monetary = pd.pivot_table(\n",
    "    invoices_df,\n",
    "    values=\"value\",\n",
    "    index=pd.Grouper(freq=\"M\"),\n",
    "    columns=\"Customer ID\",\n",
    "    aggfunc=\"max\",\n",
    "    fill_value=0\n",
    ").applymap(lambda x: 0. if x <= 0 else x)\n",
    "monetary_rolling = monetary.rolling(6, min_periods=1).sum().abs()  #ensure we have positive values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create frequency dataframe\n",
    "frequency = pd.pivot_table(\n",
    "    raw_df,\n",
    "    values=\"Quantity\",\n",
    "    aggfunc=\"sum\",\n",
    "    index=pd.Grouper(freq=\"M\"),\n",
    "    columns=\"Customer ID\",\n",
    "    fill_value=0\n",
    ").applymap(lambda x: 0.0 if x <= 0 else x)\n",
    "frequency_rolling = frequency.rolling(6, min_periods=1).sum().abs()  #ensure we have positive values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the total purchasing value for each customer each month. Next we need to create the amount of purchases the customer made in each month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recency_func(sequence):\n",
    "    \"\"\"Given a series return an array with recency values.\n",
    "    \n",
    "    0 if an element has a value.\n",
    "    n: where n is the number of cells away from the last 0\"\"\"\n",
    "    purchases = sequence > 0  # array where true means a purchase was made, false means no\n",
    "    array = []\n",
    "    for pos, purchase in enumerate(purchases):\n",
    "        if purchase:\n",
    "            array.append(0)\n",
    "        elif not purchase and pos == 0:\n",
    "            array.append(1)  # if they didn't make a purchase, and it is the beginning of our data, put a 1\n",
    "        else:\n",
    "            array.append(array[-1] + 1)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the recency dataframe\n",
    "recency = pd.pivot_table(\n",
    "    invoices_df,\n",
    "    values=\"value\",\n",
    "    aggfunc=\"count\",\n",
    "    index=pd.Grouper(freq=\"M\"),\n",
    "    columns=\"Customer ID\",\n",
    "    fill_value=0\n",
    ").apply(recency_func)\n",
    "recency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our three dataframes for RFM modeliing. Similar to a picture this is a three dimensional dataset, and if we want do any modeling with it we'll have to work on setting it up correctly. One way we can do this is by turning it into a two dimensional dataset, by unwinding the values for R F and M. Prior to doing that we should also scale our values down across the month.\n",
    "\n",
    "And for the values in our recency dataframe, we'll want to invert the values and scale it. A higher value meaning the customer made a more recent purchase.\n",
    "\n",
    "All these will be on a scale of 0 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# unpivot our dataframes and then join them all together\n",
    "_recency = pd.melt(recency.apply(minmax_scale, axis=1, raw=True).applymap(lambda x: 1-x), ignore_index=False, value_name=\"recency\", var_name=\"customer_id\")\n",
    "_frequency = pd.melt(frequency.apply(minmax_scale, axis=1, raw=True), ignore_index=False, value_name=\"freq\", var_name=\"customer_id\")\n",
    "_monetary = pd.melt(monetary.apply(minmax_scale, axis=1, raw=True), ignore_index=False, value_name=\"monetary\", var_name=\"customer_id\")\n",
    "\n",
    "_recency[\"frequency\"] = _frequency.freq\n",
    "_recency[\"monetary\"] = _monetary.monetary\n",
    "_recency[\"rolling_freq_6mo\"] = pd.melt(frequency_rolling, ignore_index=False, value_name=\"freq_rolling_6mo\", var_name=\"customer_id\").freq_rolling_6mo\n",
    "_recency[\"rolling_monetary_6mo\"] = pd.melt(monetary_rolling, ignore_index=False, value_name=\"monetary_rolling_6mo\", var_name=\"customer_id\").monetary_rolling_6mo\n",
    "\n",
    "\n",
    "result = _recency.copy()\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data in the form we want we can plot it over the course of the 25 months to see if there are any noticeable segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot the time series scatter plot\n",
    "def plot_scatter(month):\n",
    "    \"\"\"Plot the 3d scatter of customers RFM for a given month\"\"\"\n",
    "    data = result.loc[month[:-3]]\n",
    "    fig = plt.figure(figsize=(10, 16))\n",
    "    ax = plt.axes(projection=\"3d\")\n",
    "    ax.scatter(xs=data[\"recency\"], ys=data[\"frequency\"], zs=data[\"monetary\"], zdir=\"z\")\n",
    "    plt.xlabel(\"Recency\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    ax.set_zlabel(\"Monetary\")\n",
    "    plt.title(f\"RFM {month}\")\n",
    "\n",
    "months = widgets.Dropdown(options=list(result.index.unique().date.astype(str)), description=\"Month End\")\n",
    "\n",
    "interact(plot_scatter, month=months)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking through the months we can see that there is a large amount of customers which have made recent purchases (our customers in the UK), with varying amounts of frequency but mainly clustering in the 0 to .4 range. Those customers which do appear to purchase frequently also as imagined generate more monetary value.\n",
    "\n",
    "When we move over to modeling, we'll want to generate some more features to use, such as rolling features to segment our customers better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save our data\n",
    "result.to_csv(\"../data/processed/data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
